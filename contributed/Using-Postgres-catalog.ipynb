{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing DC2 data in PostgreSQL at NERSC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates use of the PostgreSQL database at NERSC.  Currently the only available dataset is the object catalog for Run1.1p.\n",
    "\n",
    "### Prerequisites\n",
    "* A file ~/.pgpass containing a line like this:\n",
    "\n",
    "`nerscdb03.nersc.gov:54432:desc_dc2_drp:desc_dc2_drp_user:`_password_\n",
    "\n",
    "This line allows you to use the desc_dc2_drp_user account, which has *SELECT* privileges on the database, without entering a password in plain text. There is a separate account for adding to or modifying the database. .pgpass must be protected so that only owner may read and write it.\n",
    " \n",
    "You can obtain the file by running the script `/global/common/software/lsst/dbaccess/postgres_reader.sh`.  It will copy a suitable file to your home directory and set permissions.  \n",
    "\n",
    "If you already have a `.pgpass` file in your home directory the script will stop without doing anything to avoid clobbering your file.  In that case, see the file `reader.pgpass` in the same directory.  You can merge it into your `.pgpass` file by hand.  \n",
    "\n",
    "* Access to the psycopg2 package which provides a Python interface to PostgreSQL. If it's not already available, do a local pip install.  Then you may have to \n",
    "  * put a line like this in your .bashrc.ext:  \n",
    "    ```$DESCPYTHONPATH=~/.local/pythonpath3.6/site-packages```\n",
    "  * restart your jupyter-dev server\n",
    "  \n",
    "This notebook uses psycopg2 directly for queries.  It is also possible to use sqlalchemy but you will still need a PostgreSQL driver. Of these psycopg2 is the most popular.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the db connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'desc_dc2_drp'\n",
    "dbuser = 'desc_dc2_drp_user'\n",
    "dbhost = 'nerscdb03.nersc.gov'\n",
    "schema = 'run12p'\n",
    "dbconfig = {'dbname' : dbname, 'user' : dbuser, 'host' : dbhost}\n",
    "dbconn = psycopg2.connect(**dbconfig)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tables for the Run1.2p data are in the *schema* (acts like a namespace) run12p. There is a special system schema, **information_schema**, which contains tables describing the structure of user tables. Of these **information_schema.columns** is most likely to be useful. The following lists all tables and views belonging to schema run11p. (I will use the convention of writing SQL keywords in all caps in queries. It's not necessary; the SQL interpreter ignores case.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"SELECT DISTINCT table_name FROM information_schema.columns WHERE table_schema='{schema}' ORDER BY table_name\".format(**locals())\n",
    "with dbconn.cursor() as cursor:\n",
    "    # Typically could have several queries in this block\n",
    "    cursor.execute(q1)\n",
    "    for record in cursor:\n",
    "        print(record[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The items with simple names, like **forced** or **meas2** are views; those starting with an underscore are the underlying tables.  The typical user will query only the views. Information is broken across several tables or views because there are too many columns for a single table. All tables and views have a field ```object_id``` which is convenient for joining when you don't know which view has the particular quantity you care about or when you need quantities from more than one view. Here is a list of all quantities in the view **forced**. It contains the most basic quantities for forced photometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = 'forced'\n",
    "q2 = \"SELECT column_name, data_type FROM information_schema.columns WHERE table_schema='{schema}' AND table_name='{tbl}'\".format(**locals())\n",
    "with dbconn.cursor() as cursor:\n",
    "    cursor.execute(q2)\n",
    "    records = cursor.fetchall()\n",
    "    print(\"There are {} columns in table {}.  They are:\\n\".format(len(records), tbl))\n",
    "    print(\"Name                                                     Data Type\")\n",
    "    for record in records:\n",
    "        print(\"{0!s:55}  {1!s:20}\".format(record[0], record[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a similar query for the **meas** view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = 'meas'\n",
    "q2 = \"SELECT column_name, data_type FROM information_schema.columns WHERE table_schema='{schema}' AND table_name='{tbl}'\".format(**locals())\n",
    "with dbconn.cursor() as cursor:\n",
    "    cursor.execute(q2)\n",
    "    records = cursor.fetchall()\n",
    "    print(\"There are {} columns in table {}.  They are:\\n\".format(len(records), tbl))\n",
    "    print(\"Name                                                     Data Type\")\n",
    "    for record in records:\n",
    "        print(\"{0!s:55}  {1!s:20}\".format(record[0], record[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a query which counts up objects per tract and stores the results (queries return a list of tuples) in a pandas DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = \"SELECT tract, COUNT(object_id) FROM {schema}.forced WHERE isprimary GROUP BY tract\".format(**locals())\n",
    "with dbconn.cursor() as cursor:\n",
    "    cursor.execute(q3)\n",
    "    df = pd.DataFrame(cursor.fetchall(), columns=['tract', 'count'])\n",
    "    print(df)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following can be compared with a similar query in the GCR Intro notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4 = \"SELECT ra,dec FROM {schema}.forced\".format(**locals())\n",
    "with dbconn.cursor() as cursor:\n",
    "    %time cursor.execute(q4)\n",
    "    %time records = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color-color\n",
    "Adapted from notebook object_pandas_stellar_locus in tutorials directory.\n",
    "#### Using cuts\n",
    "Put some cuts in a WHERE clause. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_cuts = ' isprimary '\n",
    "\n",
    "min_SNR = 25\n",
    "max_err = 1/min_SNR\n",
    "band_cuts = ' g_cmodel_magsigma < {} AND i_cmodel_magsigma < {} AND r_cmodel_magsigma < {} '.format(max_err,max_err,max_err)\n",
    "where = ' WHERE ' + global_cuts + ' AND ' + band_cuts  \n",
    "q5 = \"SELECT g_cmodel_mag AS gmag,r_cmodel_mag AS rmag,i_cmodel_mag AS imag FROM {schema}.forced \".format(**locals()) + where\n",
    "print(q5)\n",
    "records = []\n",
    "with dbconn.cursor() as cursor:\n",
    "    cursor.execute(q5)\n",
    "    records = cursor.fetchall()\n",
    "    print('{} objects found '.format(len(records)))\n",
    "    \n",
    "df = pd.DataFrame(records, columns=['g_mag', 'r_mag', 'i_mag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting\n",
    "Steal color-color plotting routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_color_color(z, color1, color2, range1=(-1, +2), range2=(-1, +2), bins=31):\n",
    "    \"\"\"Plot a color-color diagram.  Overlay stellar locus\"\"\"\n",
    "    band1, band2 = color1[0], color1[-1]\n",
    "    band3, band4 = color2[0], color2[-1]\n",
    "    H, xedges, yedges = np.histogram2d(\n",
    "        z['%s_mag' % band1] - z['%s_mag' % band2],\n",
    "        z['%s_mag' % band3] - z['%s_mag' % band4],\n",
    "        range=(range1, range2), bins=bins)\n",
    "        \n",
    "    zi = H.T\n",
    "    xi = (xedges[1:] + xedges[:-1])/2\n",
    "    yi = (yedges[1:] + yedges[:-1])/2\n",
    "\n",
    "    cmap = 'viridis_r'\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pcolormesh(xi, yi, zi, cmap=cmap)\n",
    "    plt.contour(xi, yi, zi)\n",
    "    plt.xlabel('%s-%s' % (band1, band2))\n",
    "    plt.ylabel('%s-%s' % (band3, band4))\n",
    "\n",
    "    #plot_stellar_locus(color1, color2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_color_color(df, 'gmr', 'rmi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available functions\n",
    "Many math functions from the c library have been wrapped and incorporated in an extension module installed in the database.  They have their normal c library names with the prefix `c_`.   They can be incorporated in queries as in this example using the command-line interface program **psql**:\n",
    "```\n",
    "desc_dc2_drp=> select c_asin(1.0);\n",
    "     c_asin\n",
    "-----------------\n",
    " 1.5707963267949\n",
    "```\n",
    "\n",
    "There are also functions specially crafted for HSC or LSST catalogs with suggestive names like `patch_contains`, `tract_from_object_id`, `sky_to_pixel`,.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-python",
   "language": "python",
   "name": "desc-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
